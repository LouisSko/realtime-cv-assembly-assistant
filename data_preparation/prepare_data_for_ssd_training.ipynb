{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62a877a1-add5-4c47-a1ff-0d042a4d4bbe",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "\n",
    "- Dateien Splitten\n",
    "- Augmentieren auf Training\n",
    "- Downsampling\n",
    "- Pascal VOC\n",
    "- Neue Ordnerstruktur\n",
    "- Trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "124b14c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T23:19:48.085797Z",
     "start_time": "2023-06-20T23:19:48.081060Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from create_train_test_val import split_dataset\n",
    "from image_augmentation import image_augmentation\n",
    "from downsample_images import resize_images\n",
    "from yolo_to_voc import yolo_to_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b236ec3e-f984-4db5-94ac-b6c490f4856f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify directory to the images. It should contain a directory aiss_images which contains a dir labels and images\n",
    "directory_aiss = '/pfs/data5/home/kit/stud/ulhni/aiss/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1d28cea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T23:04:35.776363Z",
     "start_time": "2023-06-20T23:04:35.734408Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 436/436 [00:25<00:00, 17.12it/s]\n",
      "100%|██████████| 54/54 [00:03<00:00, 15.51it/s]\n",
      "100%|██████████| 56/56 [00:03<00:00, 17.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# split dataset into train val test\n",
    "input_directory = os.path.join(directory_aiss, 'aiss_images')\n",
    "output_directory = os.path.join(directory_aiss, 'aiss_images')\n",
    "split_ratio = (0.8, 0.1, 0.1)\n",
    "split_dataset(input_directory, output_directory, split_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11083478-6681-4f89-949e-fc9e19a5b633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 436/436 [06:38<00:00,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# augment training images\n",
    "input_dir = os.path.join(directory_aiss, 'aiss_images', 'train')\n",
    "output_dir = os.path.join(directory_aiss, 'aiss_images', 'train')\n",
    "nr_of_augs = 2\n",
    "image_augmentation(input_dir, output_dir, nr_of_augs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a4399c9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1296/1296 [00:07<00:00, 173.96it/s]\n",
      "100%|██████████| 56/56 [00:00<00:00, 181.73it/s]\n",
      "100%|██████████| 54/54 [00:00<00:00, 172.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# resize images\n",
    "input_dir = os.path.join(directory_aiss, 'aiss_images')\n",
    "output_dir = os.path.join(directory_aiss, 'aiss_images')\n",
    "\n",
    "# Target resolution (1080p)\n",
    "max_width = 1080\n",
    "max_height = 720\n",
    "\n",
    "# resize images in all three folders\n",
    "for folder in ['train', 'val', 'test']:\n",
    "    input_dir_f = os.path.join(input_dir, folder, 'images')\n",
    "    output_dir_f = os.path.join(output_dir, folder, 'images')\n",
    "    resize_images(input_dir_f, output_dir_f, max_width, max_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b80155d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T23:14:53.436584Z",
     "start_time": "2023-06-20T23:14:50.802128Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete\n",
      "Conversion complete\n",
      "Conversion complete\n"
     ]
    }
   ],
   "source": [
    "# in each folder create a folder XML containing the voc annotations (habe den folder umbenannt von voc_annotations zu XML um konsitent zu sein mit der Bezeichnung die CVAT für die Annotation verwendet)\n",
    "input_directory = os.path.join(directory_aiss, 'aiss_images')\n",
    "\n",
    "for folder in ['train', 'val', 'test']:\n",
    "    directory_data =  os.path.join(input_directory, folder)\n",
    "    yolo_class_list_file = os.path.join(input_directory, 'classes.txt') # muss in dem Ordner abgelegt werden\n",
    "    dir_yolo_files = os.path.join(input_directory, folder, 'labels')\n",
    "    dir_images = os.path.join(input_directory, folder, 'images')\n",
    "\n",
    "    yolo_to_voc(directory_data, dir_yolo_files, dir_images, yolo_class_list_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3c987f4-4419-45be-b9a1-5e4dbed22f54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T23:19:55.331017Z",
     "start_time": "2023-06-20T23:19:54.016805Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copy the annotations into the correct directory and create the .txt files which store the information on train/test/val data\n",
    "\n",
    "# Define the paths for the three folders (train, val, test)\n",
    "train_folder =  os.path.join(directory_aiss, 'aiss_images', 'train', 'XML')\n",
    "val_folder = os.path.join(directory_aiss, 'aiss_images', 'val', 'XML')\n",
    "test_folder = os.path.join(directory_aiss, 'aiss_images', 'test', 'XML')\n",
    "\n",
    "# Define the path for the output folder\n",
    "output_folder = os.path.join(directory_aiss, 'lego/Annotations')\n",
    "imagesets_folder =  os.path.join(directory_aiss, 'lego/ImageSets/Main')\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "os.makedirs(imagesets_folder, exist_ok=True)\n",
    "\n",
    "# Initialize lists to store the filenames for each split\n",
    "train_filenames = []\n",
    "val_filenames = []\n",
    "test_filenames = []\n",
    "trainval_filenames = []\n",
    "\n",
    "# Process the val folder\n",
    "for filename in os.listdir(train_folder):\n",
    "    if filename.endswith(\".xml\"):\n",
    "        # Copy the XML file to the output folder\n",
    "        shutil.copy2(os.path.join(train_folder, filename), output_folder)\n",
    "        train_filenames.append(os.path.splitext(filename)[0])\n",
    "        trainval_filenames.append(os.path.splitext(filename)[0])\n",
    "        \n",
    "for filename in os.listdir(val_folder):\n",
    "    if filename.endswith(\".xml\"):\n",
    "        # Copy the XML file to the output folder\n",
    "        shutil.copy2(os.path.join(val_folder, filename), output_folder)\n",
    "        val_filenames.append(os.path.splitext(filename)[0])\n",
    "        trainval_filenames.append(os.path.splitext(filename)[0])\n",
    "        #print(os.path.splitext(filename)[0])\n",
    "# Process the test folder\n",
    "for filename in os.listdir(test_folder):\n",
    "    if filename.endswith(\".xml\"):\n",
    "        # Copy the XML file to the output folder\n",
    "        shutil.copy2(os.path.join(test_folder, filename), output_folder)\n",
    "        test_filenames.append(os.path.splitext(filename)[0])\n",
    "        #print(os.path.splitext(filename)[0])\n",
    "\n",
    "with open(os.path.join(imagesets_folder, \"train.txt\"), \"w\") as train_file:\n",
    "    train_file.write(\"\\n\".join(train_filenames))        \n",
    "        \n",
    "with open(os.path.join(imagesets_folder, \"val.txt\"), \"w\") as val_file:\n",
    "    val_file.write(\"\\n\".join(val_filenames))\n",
    "\n",
    "with open(os.path.join(imagesets_folder, \"test.txt\"), \"w\") as test_file:\n",
    "    test_file.write(\"\\n\".join(test_filenames))\n",
    "    \n",
    "with open(os.path.join(imagesets_folder, \"trainval.txt\"), \"w\") as trainval_file:\n",
    "    trainval_file.write(\"\\n\".join(trainval_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81f61637-62a7-49e2-af31-b1cf5b32be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the image files into the JPEGImages directory\n",
    "input_dir = os.path.join(directory_aiss, 'aiss_images')\n",
    "output_dir = os.path.join(directory_aiss, 'aiss_images')\n",
    "\n",
    "# Define the path for the output folder\n",
    "output_folder = os.path.join(directory_aiss, 'data/lego/JPEGImages')\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for folder in ['train', 'val', 'test']:\n",
    "    directory = os.path.join(input_dir, folder, 'images')\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpeg\"):\n",
    "            # Copy the image file to the output folder\n",
    "            shutil.copy2(os.path.join(directory, filename), output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64afd19e-d203-4c40-a771-da8cd0cfeff3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/pfs/data5/home/kit/stud/ulhni/aiss/object-detection-project/pytorch-ssd/data/lego'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy the entire lego directory and its contents to the destination\n",
    "# inp = '/pfs/data5/home/kit/stud/ulhni/aiss/lego'\n",
    "# out = '/pfs/data5/home/kit/stud/ulhni/aiss/object-detection-project/pytorch-ssd/data'\n",
    "\n",
    "# shutil.copytree(inp, os.path.join(out, 'lego'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16df4c9c-dac5-4d5a-883c-96c4c2bb4b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiss_kernel",
   "language": "python",
   "name": "aiss_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
